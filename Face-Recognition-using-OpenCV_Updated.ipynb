{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries for completing the project\n",
    "- cv2 for computer vision\n",
    "- numpy for handling the array operartion\n",
    "- os for handling the file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training....\n",
      "[[[ 82  84  86 ... 115 117 118]\n",
      "  [ 84  86  89 ... 118 117 118]\n",
      "  [ 86  88  91 ... 116 116 117]\n",
      "  ...\n",
      "  [111 111 112 ... 105 104 103]\n",
      "  [111 110 110 ... 106 105 104]\n",
      "  [109 109 111 ... 104 103 102]]\n",
      "\n",
      " [[ 82  84  85 ... 115 117 119]\n",
      "  [ 86  87  89 ... 113 116 118]\n",
      "  [ 84  85  89 ... 117 117 119]\n",
      "  ...\n",
      "  [109 109 112 ... 100 102 104]\n",
      "  [110 108 111 ... 101 101 101]\n",
      "  [109 107 112 ... 103 100  99]]\n",
      "\n",
      " [[ 87  89  89 ... 119 117 117]\n",
      "  [ 89  86  86 ... 119 117 117]\n",
      "  [ 89  87  85 ... 117 116 116]\n",
      "  ...\n",
      "  [109 111 114 ...  99  99  98]\n",
      "  [110 113 116 ... 100  97  96]\n",
      "  [108 112 116 ... 100  95  94]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[112 113 115 ... 174 173 173]\n",
      "  [115 122 113 ... 173 173 173]\n",
      "  [117 118 112 ... 172 174 174]\n",
      "  ...\n",
      "  [ 38  37  37 ...  75  74  84]\n",
      "  [ 39  38  38 ...  68  73  79]\n",
      "  [ 40  40  40 ...  68  67  70]]\n",
      "\n",
      " [[121 122 123 ... 173 172 172]\n",
      "  [126 124 122 ... 173 173 173]\n",
      "  [126 125 121 ... 174 173 173]\n",
      "  ...\n",
      "  [ 78  68  76 ...  66  70  71]\n",
      "  [ 90  81  84 ...  71  68  66]\n",
      "  [101  91  88 ...  77  70  65]]\n",
      "\n",
      " [[111 117 112 ... 173 175 175]\n",
      "  [115 119 108 ... 173 173 173]\n",
      "  [115 119 110 ... 171 172 172]\n",
      "  ...\n",
      "  [ 41  37  37 ...  76  70  81]\n",
      "  [ 38  35  37 ...  69  70  76]\n",
      "  [ 36  34  37 ...  70  70  74]]] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n",
      "towhid\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2, numpy, os\n",
    "\n",
    "# Loading haarcasacde algorithm for detecting the face\n",
    "haar_file = 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "\n",
    "dataset = 'dataset'\n",
    "print('Training....')\n",
    "\n",
    "# Taking some other variables to take data from the dataset\n",
    "\n",
    "(images,labels,names,id) = ([],[],{},0) # here []--> means array, {}-->means set, 0 means first subdir\n",
    "\n",
    "# Directory processing--> going to append the dataset into a single array..\n",
    "# Going to get the files, their id and their names from the directory\n",
    "\n",
    "for (subdirs, dirs, files) in os.walk(dataset): #Entering into the dataset folder\n",
    "    for subdir in dirs:\n",
    "        names[id] = subdir # Assign subdir to each id by its name. subdir are the user name\n",
    "        subjectpath = os.path.join(dataset, subdir) #searching the path of subdir\n",
    "        for filename in os.listdir(subjectpath): #Reading the files inside the subdir\n",
    "            \n",
    "            #path of a specific subforlder\n",
    "            path = subjectpath + '/' + filename\n",
    "            label = id # assign id as label. label=0 -->1st person, label=1-->2nd person\n",
    "            images.append(cv2.imread(path,0)) # Taking the id->0 images into an array\n",
    "            labels.append(int(label)) # Taking the label in an array\n",
    "        id = id + 1\n",
    "\n",
    "#Put images and labels into an array. Converting everything into list        \n",
    "(images,labels) = [numpy.array(lis) for lis in [images,labels]]\n",
    "print(images, labels)\n",
    "(width,height) = (130,100)\n",
    "\n",
    "# Initializing the classifier for recognition..\n",
    "\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "#model = cv2.face.FisherFaceRecognizer_create()\n",
    "\n",
    "#Creating a training model..\n",
    "model.train(images, labels)\n",
    "\n",
    "#Obtaining the image from the camera\n",
    "webcam = cv2.VideoCapture(0) #Initializing the camear\n",
    "cnt = 0\n",
    "\n",
    "while True:\n",
    "    (_,im) = webcam.read() #Read the frame\n",
    "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) #Convert the frame into gray image\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5) # Taking the face coordinates\n",
    "    \n",
    "    #To obtain the face. Where the face is located\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),(255,255,0),2) #Drawing rectangle around the face\n",
    "        face = gray[y:y+h,x:x+w] #Converting into gray and crop only the face part\n",
    "        face_resize = cv2.resize(face,(width,height)) #Resizing\n",
    "\n",
    "        prediction = model.predict(face_resize) #For prediction. Return the accuracy and the label id\n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),(255,255,0),2) #Drawing rectangle ahape\n",
    "        \n",
    "        #Checking the prediction\n",
    "        #Only freater than some value, then it will be a predicted person.\n",
    "        #It will try to compare captured image with the database and give the prediction\n",
    "        if prediction[1] < 800: #For more accuracy, have to increase this value\n",
    "            cv2.putText(im,'%s - %.0f' % (names[prediction[0]],prediction[1]),(x-10,y-10),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255))\n",
    "            print(names[prediction[0]]) #Prediction[0] means the id\n",
    "            cnt = 0\n",
    "            \n",
    "        else: #For unknown people. If value is found greater than 100. The person should be unknown\n",
    "            cnt += 1\n",
    "            cv2.putText(im,'Unknown',(x-10,y-10),cv2.FONT_HERSHEY_PLAIN,1,(0,255,0))\n",
    "            if cnt > 100:\n",
    "                print(\"Unknown Person\")\n",
    "                cv2.imwrite(\"Unknown.jpg\",im) #Write the unknown image into the dataset\n",
    "                cnt = 0\n",
    "    cv2.imshow('FaceRecognition',im) #For showing the frame\n",
    "    \n",
    "    #For terminating the window\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord (\"q\"):\n",
    "        break\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![output](./image/output.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
